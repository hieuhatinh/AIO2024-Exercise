{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstFeature(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3, \n",
    "                padding=1, \n",
    "                stride=1\n",
    "            ), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class FeatureOut(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3, \n",
    "                padding=1, \n",
    "                stride=1\n",
    "            ),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3, \n",
    "                padding=1, \n",
    "                stride=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels, \n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1, \n",
    "                stride=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            ConvBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.trans_conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels,\n",
    "            kernel_size=4, \n",
    "            padding=1, \n",
    "            stride=2\n",
    "        )\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        up_sample = self.trans_conv(x)\n",
    "        concat = torch.concat([up_sample, skip], dim=1)\n",
    "        return self.conv_block(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_IMG_WIDTH = 64\n",
    "LOW_IMG_HEIGHT = 64\n",
    "\n",
    "class UNetArchitecture(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes):\n",
    "        super().__init__()\n",
    "        self.resize = transforms.Resize((LOW_IMG_WIDTH*4, LOW_IMG_HEIGHT*4))\n",
    "        self.first_feature = FirstFeature(in_channels, 64)\n",
    "        self.conv = ConvBlock(64, 64)\n",
    "        \n",
    "        self.encoder1 = Encoder(64, 128)\n",
    "        self.encoder2 = Encoder(128, 256)\n",
    "        self.encoder3 = Encoder(256, 512)\n",
    "        self.encoder4 = Encoder(512, 1024)\n",
    "\n",
    "        self.decoder1 = Decoder(1024, 512)\n",
    "        self.decoder2 = Decoder(512, 256)\n",
    "        self.decoder3 = Decoder(256, 128)\n",
    "        self.decoder4 = Decoder(128, 64)\n",
    "\n",
    "        self.out_conv = FeatureOut(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resize(x)\n",
    "        x = self.first_feature(x)\n",
    "        print(f'shape first feature: {x.shape}')\n",
    "        x1 = self.conv(x)\n",
    "        print(f'shape x1: {x1.shape}')\n",
    "\n",
    "        x2 = self.encoder1(x1)\n",
    "        print(f'shape encoder x2: {x2.shape}')\n",
    "        x3 = self.encoder2(x2)\n",
    "        print(f'shape encoder x3: {x3.shape}')\n",
    "        x4 = self.encoder3(x3)\n",
    "        print(f'shape encoder x4: {x4.shape}')\n",
    "        x5 = self.encoder4(x4)\n",
    "        print(f'shape encoder x5: {x5.shape}')\n",
    "\n",
    "        x = self.decoder1(x5, x4)\n",
    "        print(f'shape decoder 1: {x.shape}')\n",
    "        x = self.decoder2(x, x3)\n",
    "        print(f'shape decoder 2: {x.shape}')\n",
    "        x = self.decoder3(x, x2)\n",
    "        print(f'shape decoder 3: {x.shape}')\n",
    "        x = self.decoder4(x, x1)\n",
    "        print(f'shape decoder 4: {x.shape}')\n",
    "        x = self.out_conv(x)\n",
    "        print(f'shape out conv: {x.shape}')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape first feature: torch.Size([4, 64, 256, 256])\n",
      "shape x1: torch.Size([4, 64, 256, 256])\n",
      "shape encoder x2: torch.Size([4, 128, 128, 128])\n",
      "shape encoder x3: torch.Size([4, 256, 64, 64])\n",
      "shape encoder x4: torch.Size([4, 512, 32, 32])\n",
      "shape encoder x5: torch.Size([4, 1024, 16, 16])\n",
      "shape decoder 1: torch.Size([4, 512, 32, 32])\n",
      "shape decoder 2: torch.Size([4, 256, 64, 64])\n",
      "shape decoder 3: torch.Size([4, 128, 128, 128])\n",
      "shape decoder 4: torch.Size([4, 64, 256, 256])\n",
      "shape out conv: torch.Size([4, 2, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1433, -0.2242, -0.5637,  ...,  0.1078,  0.1862,  0.7400],\n",
       "          [-0.2610, -0.8039, -0.7532,  ..., -0.8516, -0.8647, -0.3065],\n",
       "          [-0.0292, -0.3885, -0.0425,  ...,  0.2194, -0.3052,  0.3159],\n",
       "          ...,\n",
       "          [-0.1970, -0.4950, -0.6204,  ..., -0.9535, -0.7123, -0.1046],\n",
       "          [-0.6517, -0.7018, -0.7071,  ..., -0.7859, -0.5010,  0.3958],\n",
       "          [-0.1124, -0.3615, -0.0480,  ...,  0.4445, -0.3803, -0.7965]],\n",
       "\n",
       "         [[ 0.0805,  0.3043,  0.0340,  ...,  0.6672,  0.8679,  0.5566],\n",
       "          [-0.3556,  0.7558,  0.1532,  ...,  0.1599,  0.6567, -0.1257],\n",
       "          [ 0.2095,  0.9350,  0.7475,  ..., -0.2127,  0.5512,  0.6668],\n",
       "          ...,\n",
       "          [ 0.4086,  0.8987,  0.5008,  ...,  0.8472,  0.8808,  0.3018],\n",
       "          [ 0.3362,  0.6182,  0.0857,  ...,  0.6929,  0.9397,  0.6147],\n",
       "          [-0.0857,  0.4706,  0.6132,  ...,  0.0412,  0.4414,  0.0296]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1883, -0.2245, -0.3318,  ..., -0.0749,  0.1616,  0.3922],\n",
       "          [ 0.2487, -0.6526, -0.6851,  ...,  0.1608, -0.3079, -0.0345],\n",
       "          [-0.2580,  0.0757,  0.2030,  ..., -0.1713,  0.1017,  0.4022],\n",
       "          ...,\n",
       "          [ 0.6717, -0.8299, -0.7973,  ..., -0.3925,  0.0109, -0.2561],\n",
       "          [ 0.0342, -0.7833, -0.9301,  ..., -0.6712, -0.4906, -0.1829],\n",
       "          [-0.1004, -0.1458,  0.0422,  ...,  0.2071, -0.3708, -0.2236]],\n",
       "\n",
       "         [[ 0.3374,  0.4540,  0.0335,  ...,  0.6339,  0.6925,  0.1195],\n",
       "          [-0.1655,  0.6725,  0.5304,  ..., -0.0974,  0.3636,  0.0386],\n",
       "          [ 0.5243,  0.9149, -0.1098,  ...,  0.4488,  0.4539,  0.6228],\n",
       "          ...,\n",
       "          [ 0.5301,  0.9737,  0.9459,  ...,  0.4432, -0.0864, -0.1848],\n",
       "          [ 0.5155,  0.3826,  0.0929,  ...,  0.3816,  0.5978,  0.0646],\n",
       "          [ 0.0062,  0.2934,  0.5138,  ...,  0.3998,  0.3981,  0.5361]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0845,  0.1055, -0.0568,  ..., -0.1359,  0.0451,  0.4631],\n",
       "          [-0.1397, -0.9536, -0.9728,  ..., -0.3000, -0.4947, -0.4062],\n",
       "          [ 0.1798, -0.8912, -0.6185,  ..., -0.0250, -0.3747,  0.0422],\n",
       "          ...,\n",
       "          [ 0.4816, -0.7288, -0.7975,  ..., -0.9399, -0.6465,  0.3041],\n",
       "          [-0.3776, -0.8950, -0.9727,  ..., -0.8974, -0.8323,  0.2187],\n",
       "          [-0.3910, -0.4483, -0.3850,  ...,  0.5101, -0.4533, -0.8584]],\n",
       "\n",
       "         [[ 0.6449,  0.6109,  0.6962,  ...,  0.6738,  0.8326,  0.4488],\n",
       "          [ 0.2646,  0.9876,  0.9654,  ...,  0.4344,  0.6797,  0.0579],\n",
       "          [ 0.5367,  0.7439,  0.2290,  ...,  0.5705,  0.4027,  0.6749],\n",
       "          ...,\n",
       "          [ 0.6805,  0.9785,  0.8700,  ...,  0.7876,  0.6380,  0.2611],\n",
       "          [ 0.5066,  0.3094,  0.1578,  ...,  0.8059,  0.8819,  0.7048],\n",
       "          [ 0.0744,  0.2860,  0.3446,  ..., -0.0669,  0.3921,  0.0311]]],\n",
       "\n",
       "\n",
       "        [[[-0.0583, -0.2558, -0.2933,  ..., -0.0672,  0.2374,  0.5150],\n",
       "          [-0.4758, -0.7512, -0.5785,  ..., -0.3751, -0.4484, -0.6212],\n",
       "          [-0.2700, -0.5606,  0.0357,  ...,  0.2952, -0.3345,  0.2138],\n",
       "          ...,\n",
       "          [ 0.5207, -0.8713, -0.8583,  ..., -0.8044, -0.3686,  0.0666],\n",
       "          [ 0.0571, -0.8251, -0.9346,  ..., -0.7716, -0.7606,  0.3555],\n",
       "          [-0.2508, -0.3113,  0.2865,  ...,  0.4747, -0.4368, -0.7358]],\n",
       "\n",
       "         [[-0.3173,  0.3898,  0.3243,  ...,  0.3333,  0.6540,  0.0583],\n",
       "          [-0.4003,  0.7680,  0.5587,  ...,  0.0276, -0.1689,  0.0226],\n",
       "          [-0.0680,  0.8945,  0.7602,  ...,  0.0025,  0.4166,  0.5177],\n",
       "          ...,\n",
       "          [-0.0495,  0.8407,  0.9102,  ...,  0.4252,  0.4843,  0.0604],\n",
       "          [ 0.4096,  0.3900,  0.0834,  ...,  0.5167,  0.7840,  0.4427],\n",
       "          [ 0.3151,  0.5246,  0.3931,  ...,  0.2925,  0.5248,  0.0082]]]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(\n",
    "    5, (4, 1, 64, 64), dtype=torch.float32\n",
    ")\n",
    "\n",
    "model = UNetArchitecture(in_channels=1, n_classes=2)\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FPTSHOP\\miniconda3\\envs\\aio2024-exercise\\Lib\\site-packages\\torch\\cuda\\__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape first feature: torch.Size([2, 64, 256, 256])\n",
      "shape x1: torch.Size([2, 64, 256, 256])\n",
      "shape encoder x2: torch.Size([2, 128, 128, 128])\n",
      "shape encoder x3: torch.Size([2, 256, 64, 64])\n",
      "shape encoder x4: torch.Size([2, 512, 32, 32])\n",
      "shape encoder x5: torch.Size([2, 1024, 16, 16])\n",
      "shape decoder 1: torch.Size([2, 512, 32, 32])\n",
      "shape decoder 2: torch.Size([2, 256, 64, 64])\n",
      "shape decoder 3: torch.Size([2, 128, 128, 128])\n",
      "shape decoder 4: torch.Size([2, 64, 256, 256])\n",
      "shape out conv: torch.Size([2, 3, 256, 256])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Resize: 1-1                            [-1, 3, 256, 256]         --\n",
      "├─FirstFeature: 1-2                      [-1, 64, 256, 256]        --\n",
      "|    └─Sequential: 2-1                   [-1, 64, 256, 256]        --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 256, 256]        1,792\n",
      "|    |    └─ReLU: 3-2                    [-1, 64, 256, 256]        --\n",
      "├─ConvBlock: 1-3                         [-1, 64, 256, 256]        --\n",
      "|    └─Sequential: 2-2                   [-1, 64, 256, 256]        --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 64, 256, 256]        36,928\n",
      "|    |    └─BatchNorm2d: 3-4             [-1, 64, 256, 256]        128\n",
      "|    |    └─ReLU: 3-5                    [-1, 64, 256, 256]        --\n",
      "|    |    └─Conv2d: 3-6                  [-1, 64, 256, 256]        36,928\n",
      "|    |    └─BatchNorm2d: 3-7             [-1, 64, 256, 256]        128\n",
      "|    |    └─ReLU: 3-8                    [-1, 64, 256, 256]        --\n",
      "├─Encoder: 1-4                           [-1, 128, 128, 128]       --\n",
      "|    └─Sequential: 2-3                   [-1, 128, 128, 128]       --\n",
      "|    |    └─MaxPool2d: 3-9               [-1, 64, 128, 128]        --\n",
      "|    |    └─ConvBlock: 3-10              [-1, 128, 128, 128]       221,952\n",
      "├─Encoder: 1-5                           [-1, 256, 64, 64]         --\n",
      "|    └─Sequential: 2-4                   [-1, 256, 64, 64]         --\n",
      "|    |    └─MaxPool2d: 3-11              [-1, 128, 64, 64]         --\n",
      "|    |    └─ConvBlock: 3-12              [-1, 256, 64, 64]         886,272\n",
      "├─Encoder: 1-6                           [-1, 512, 32, 32]         --\n",
      "|    └─Sequential: 2-5                   [-1, 512, 32, 32]         --\n",
      "|    |    └─MaxPool2d: 3-13              [-1, 256, 32, 32]         --\n",
      "|    |    └─ConvBlock: 3-14              [-1, 512, 32, 32]         3,542,016\n",
      "├─Encoder: 1-7                           [-1, 1024, 16, 16]        --\n",
      "|    └─Sequential: 2-6                   [-1, 1024, 16, 16]        --\n",
      "|    |    └─MaxPool2d: 3-15              [-1, 512, 16, 16]         --\n",
      "|    |    └─ConvBlock: 3-16              [-1, 1024, 16, 16]        14,161,920\n",
      "├─Decoder: 1-8                           [-1, 512, 32, 32]         --\n",
      "|    └─ConvTranspose2d: 2-7              [-1, 512, 32, 32]         8,389,120\n",
      "|    └─ConvBlock: 2-8                    [-1, 512, 32, 32]         --\n",
      "|    |    └─Sequential: 3-17             [-1, 512, 32, 32]         7,080,960\n",
      "├─Decoder: 1-9                           [-1, 256, 64, 64]         --\n",
      "|    └─ConvTranspose2d: 2-9              [-1, 256, 64, 64]         2,097,408\n",
      "|    └─ConvBlock: 2-10                   [-1, 256, 64, 64]         --\n",
      "|    |    └─Sequential: 3-18             [-1, 256, 64, 64]         1,771,008\n",
      "├─Decoder: 1-10                          [-1, 128, 128, 128]       --\n",
      "|    └─ConvTranspose2d: 2-11             [-1, 128, 128, 128]       524,416\n",
      "|    └─ConvBlock: 2-12                   [-1, 128, 128, 128]       --\n",
      "|    |    └─Sequential: 3-19             [-1, 128, 128, 128]       443,136\n",
      "├─Decoder: 1-11                          [-1, 64, 256, 256]        --\n",
      "|    └─ConvTranspose2d: 2-13             [-1, 64, 256, 256]        131,136\n",
      "|    └─ConvBlock: 2-14                   [-1, 64, 256, 256]        --\n",
      "|    |    └─Sequential: 3-20             [-1, 64, 256, 256]        110,976\n",
      "├─FeatureOut: 1-12                       [-1, 3, 256, 256]         --\n",
      "|    └─Sequential: 2-15                  [-1, 3, 256, 256]         --\n",
      "|    |    └─Conv2d: 3-21                 [-1, 3, 256, 256]         1,731\n",
      "|    |    └─Tanh: 3-22                   [-1, 3, 256, 256]         --\n",
      "==========================================================================================\n",
      "Total params: 39,437,955\n",
      "Trainable params: 39,437,955\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 68.52\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 461.50\n",
      "Params size (MB): 150.44\n",
      "Estimated Total Size (MB): 611.99\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Resize: 1-1                            [-1, 3, 256, 256]         --\n",
       "├─FirstFeature: 1-2                      [-1, 64, 256, 256]        --\n",
       "|    └─Sequential: 2-1                   [-1, 64, 256, 256]        --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 256, 256]        1,792\n",
       "|    |    └─ReLU: 3-2                    [-1, 64, 256, 256]        --\n",
       "├─ConvBlock: 1-3                         [-1, 64, 256, 256]        --\n",
       "|    └─Sequential: 2-2                   [-1, 64, 256, 256]        --\n",
       "|    |    └─Conv2d: 3-3                  [-1, 64, 256, 256]        36,928\n",
       "|    |    └─BatchNorm2d: 3-4             [-1, 64, 256, 256]        128\n",
       "|    |    └─ReLU: 3-5                    [-1, 64, 256, 256]        --\n",
       "|    |    └─Conv2d: 3-6                  [-1, 64, 256, 256]        36,928\n",
       "|    |    └─BatchNorm2d: 3-7             [-1, 64, 256, 256]        128\n",
       "|    |    └─ReLU: 3-8                    [-1, 64, 256, 256]        --\n",
       "├─Encoder: 1-4                           [-1, 128, 128, 128]       --\n",
       "|    └─Sequential: 2-3                   [-1, 128, 128, 128]       --\n",
       "|    |    └─MaxPool2d: 3-9               [-1, 64, 128, 128]        --\n",
       "|    |    └─ConvBlock: 3-10              [-1, 128, 128, 128]       221,952\n",
       "├─Encoder: 1-5                           [-1, 256, 64, 64]         --\n",
       "|    └─Sequential: 2-4                   [-1, 256, 64, 64]         --\n",
       "|    |    └─MaxPool2d: 3-11              [-1, 128, 64, 64]         --\n",
       "|    |    └─ConvBlock: 3-12              [-1, 256, 64, 64]         886,272\n",
       "├─Encoder: 1-6                           [-1, 512, 32, 32]         --\n",
       "|    └─Sequential: 2-5                   [-1, 512, 32, 32]         --\n",
       "|    |    └─MaxPool2d: 3-13              [-1, 256, 32, 32]         --\n",
       "|    |    └─ConvBlock: 3-14              [-1, 512, 32, 32]         3,542,016\n",
       "├─Encoder: 1-7                           [-1, 1024, 16, 16]        --\n",
       "|    └─Sequential: 2-6                   [-1, 1024, 16, 16]        --\n",
       "|    |    └─MaxPool2d: 3-15              [-1, 512, 16, 16]         --\n",
       "|    |    └─ConvBlock: 3-16              [-1, 1024, 16, 16]        14,161,920\n",
       "├─Decoder: 1-8                           [-1, 512, 32, 32]         --\n",
       "|    └─ConvTranspose2d: 2-7              [-1, 512, 32, 32]         8,389,120\n",
       "|    └─ConvBlock: 2-8                    [-1, 512, 32, 32]         --\n",
       "|    |    └─Sequential: 3-17             [-1, 512, 32, 32]         7,080,960\n",
       "├─Decoder: 1-9                           [-1, 256, 64, 64]         --\n",
       "|    └─ConvTranspose2d: 2-9              [-1, 256, 64, 64]         2,097,408\n",
       "|    └─ConvBlock: 2-10                   [-1, 256, 64, 64]         --\n",
       "|    |    └─Sequential: 3-18             [-1, 256, 64, 64]         1,771,008\n",
       "├─Decoder: 1-10                          [-1, 128, 128, 128]       --\n",
       "|    └─ConvTranspose2d: 2-11             [-1, 128, 128, 128]       524,416\n",
       "|    └─ConvBlock: 2-12                   [-1, 128, 128, 128]       --\n",
       "|    |    └─Sequential: 3-19             [-1, 128, 128, 128]       443,136\n",
       "├─Decoder: 1-11                          [-1, 64, 256, 256]        --\n",
       "|    └─ConvTranspose2d: 2-13             [-1, 64, 256, 256]        131,136\n",
       "|    └─ConvBlock: 2-14                   [-1, 64, 256, 256]        --\n",
       "|    |    └─Sequential: 3-20             [-1, 64, 256, 256]        110,976\n",
       "├─FeatureOut: 1-12                       [-1, 3, 256, 256]         --\n",
       "|    └─Sequential: 2-15                  [-1, 3, 256, 256]         --\n",
       "|    |    └─Conv2d: 3-21                 [-1, 3, 256, 256]         1,731\n",
       "|    |    └─Tanh: 3-22                   [-1, 3, 256, 256]         --\n",
       "==========================================================================================\n",
       "Total params: 39,437,955\n",
       "Trainable params: 39,437,955\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 68.52\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 461.50\n",
       "Params size (MB): 150.44\n",
       "Estimated Total Size (MB): 611.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = UNetArchitecture(in_channels=3, n_classes=3)\n",
    "summary(model, (3, 64, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024-exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
