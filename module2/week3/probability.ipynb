{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play tennis classifier implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    data = [['Sunny', 'Hot', 'High', 'Weak', 'no'],\n",
    "            ['Sunny', 'Hot', 'High', 'Strong', 'no'],\n",
    "            ['Overcast', 'Hot', 'High', 'Weak', 'yes'],\n",
    "            ['Rain', 'Mild', 'High', 'Weak', 'yes'],\n",
    "            ['Rain', 'Cool', 'Normal', 'Weak', 'yes'],\n",
    "            ['Rain', 'Cool', 'Normal', 'Strong', 'no'],\n",
    "            ['Overcast', 'Cool', 'Normal', 'Strong', 'yes'],\n",
    "            ['Overcast', 'Mild', 'High', 'Weak', 'no'],\n",
    "            ['Sunny', 'Cool', 'Normal', 'Weak', 'yes'],\n",
    "            ['Rain', 'Mild', 'Normal', 'Weak', 'yes']]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3], dtype=int64),)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes_data = train_data[np.where(train_data[:, -1] == 'yes')]\n",
    "np.where(yes_data[:, 0] == 'Overcast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prior_proability(train_data):\n",
    "    _, counts = np.unique(train_data[:, -1], return_counts=True)\n",
    "    # prior_probability = np.zeros(len(unique))\n",
    "    # unique_counts = dict(zip(unique, counts))\n",
    "    total_rows = np.sum(counts)\n",
    "    prior_probability = counts/total_rows\n",
    "    return prior_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.6]\n",
      "P(play tennis = No) 0.4\n",
      "P(play tennis = Yes) 0.6\n"
     ]
    }
   ],
   "source": [
    "prior_probability = compute_prior_proability(train_data)\n",
    "print(prior_probability)\n",
    "print(\"P(play tennis = No)\", prior_probability[0])\n",
    "print(\"P(play tennis = Yes)\", prior_probability[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_probability(train_data):\n",
    "    y_unique = ['no', 'yes']\n",
    "    conditional_probability = []\n",
    "    list_x_name = []\n",
    "    for i in range(0, train_data.shape[1]-1):\n",
    "        x_unique = np.unique(train_data[:, i])\n",
    "        list_x_name.append(x_unique)\n",
    "\n",
    "        # Tính xác suất có điều kiện cho từng giá trị của biến mục tiêu\n",
    "        x_conditional_probability = []\n",
    "        for unique in y_unique:\n",
    "            # Lọc dữ liệu theo giá trị của 'Play Tennis'= 'yes' / 'no'\n",
    "            data_features_unique = train_data[train_data[:, -1] == unique]\n",
    "            # Tính xác suất có điều kiện cho từng giá trị của đặc trưng theo 'Play Tennis'= 'yes' / 'no'\n",
    "            feature_conditional_probability = []\n",
    "            for x_name in x_unique:\n",
    "                x_conditional = np.nonzero(\n",
    "                    data_features_unique[:, i] == x_name)[0]\n",
    "                probability = len(x_conditional) / len(data_features_unique)\n",
    "                feature_conditional_probability.append(probability)\n",
    "            x_conditional_probability.append(feature_conditional_probability)\n",
    "            convert_to_np = np.array(x_conditional_probability)\n",
    "        conditional_probability.append(convert_to_np)\n",
    "    return conditional_probability, list_x_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 =  ['Overcast' 'Rain' 'Sunny']\n",
      "x2 =  ['Cool' 'Hot' 'Mild']\n",
      "x3 =  ['High' 'Normal']\n",
      "x4 =  ['Strong' 'Weak']\n"
     ]
    }
   ],
   "source": [
    "_, list_x_name = compute_conditional_probability(train_data)\n",
    "print('x1 = ', list_x_name[0])\n",
    "print('x2 = ', list_x_name[1])\n",
    "print('x3 = ', list_x_name[2])\n",
    "print('x4 = ', list_x_name[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_from_value(feature_name, list_features):\n",
    "    return np.where(list_features == feature_name)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "outlook = list_x_name[0]\n",
    "i1 = get_index_from_value('Overcast', outlook)\n",
    "i2 = get_index_from_value('Rain', outlook)\n",
    "i3 = get_index_from_value('Sunny', outlook)\n",
    "print(i1, i2, i3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('Outlook'= 'Sunny'| Play Tennis'= 'Yes') =  0.17\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()\n",
    "conditional_probability, list_x_name = compute_conditional_probability(\n",
    "    train_data)\n",
    "x1 = get_index_from_value('Sunny', list_x_name[0])\n",
    "print(\"P('Outlook'= 'Sunny'| Play Tennis'= 'Yes') = \", np.round(conditional_probability\n",
    "                                                                [0][1, x1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('Outlook'= 'Sunny'| Play Tennis'= 'No') =  0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"P('Outlook'= 'Sunny'| Play Tennis'= 'No') = \", np.round(conditional_probability\n",
    "                                                               [0][0][x1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(train_data):\n",
    "    # Step 1: Calculate Prior Probability\n",
    "    y_unique = ['no', 'yes']\n",
    "    prior_probability = compute_prior_proability(train_data)\n",
    "\n",
    "    #  Step 2: Calculate Conditional Probability\n",
    "    conditional_probability, list_x_name = compute_conditional_probability(\n",
    "        train_data)\n",
    "    return prior_probability, conditional_probability, list_x_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################\n",
    "# Prediction\n",
    "# ###################\n",
    "def prediction_play_tennis(X, list_x_name, prior_probability, conditional_probability):\n",
    "    x1 = get_index_from_value(X[0], list_x_name[0])\n",
    "    x2 = get_index_from_value(X[1], list_x_name[1])\n",
    "    x3 = get_index_from_value(X[2], list_x_name[2])\n",
    "    x4 = get_index_from_value(X[3], list_x_name[3])\n",
    "\n",
    "    p0 = prior_probability[0] \\\n",
    "        * conditional_probability[0][0, x1] \\\n",
    "        * conditional_probability[1][0, x2] \\\n",
    "        * conditional_probability[2][0, x3] \\\n",
    "        * conditional_probability[3][0, x4]\n",
    "\n",
    "    p1 = prior_probability[1] \\\n",
    "        * conditional_probability[0][1, x1] \\\n",
    "        * conditional_probability[1][1, x2] \\\n",
    "        * conditional_probability[2][1, x3] \\\n",
    "        * conditional_probability[3][1, x4]\n",
    "    if p0 > p1:\n",
    "        y_pred = 0\n",
    "    else:\n",
    "        y_pred = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad should not go!\n"
     ]
    }
   ],
   "source": [
    "X = ['Sunny', 'Cool', 'High', 'Strong']\n",
    "data = create_train_data()\n",
    "prior_probability, conditional_probability, list_x_name_2 = train_naive_bayes(\n",
    "    data)\n",
    "pred = prediction_play_tennis(\n",
    "    X, list_x_name, prior_probability, conditional_probability)\n",
    "\n",
    "if (pred):\n",
    "    print(\"Ad should go!\")\n",
    "else:\n",
    "    print(\"Ad should not go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris classifier implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    data = np.loadtxt('./iris.data.txt', dtype=str, delimiter=',')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['4.9', '3.0', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'],\n",
       "       ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'],\n",
       "       ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['5.4', '3.9', '1.7', '0.4', 'Iris-setosa'],\n",
       "       ['4.6', '3.4', '1.4', '0.3', 'Iris-setosa'],\n",
       "       ['5.0', '3.4', '1.5', '0.2', 'Iris-setosa'],\n",
       "       ['4.4', '2.9', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'],\n",
       "       ['5.4', '3.7', '1.5', '0.2', 'Iris-setosa'],\n",
       "       ['4.8', '3.4', '1.6', '0.2', 'Iris-setosa'],\n",
       "       ['4.8', '3.0', '1.4', '0.1', 'Iris-setosa'],\n",
       "       ['4.3', '3.0', '1.1', '0.1', 'Iris-setosa'],\n",
       "       ['5.8', '4.0', '1.2', '0.2', 'Iris-setosa'],\n",
       "       ['5.7', '4.4', '1.5', '0.4', 'Iris-setosa'],\n",
       "       ['5.4', '3.9', '1.3', '0.4', 'Iris-setosa'],\n",
       "       ['5.1', '3.5', '1.4', '0.3', 'Iris-setosa'],\n",
       "       ['5.7', '3.8', '1.7', '0.3', 'Iris-setosa'],\n",
       "       ['5.1', '3.8', '1.5', '0.3', 'Iris-setosa'],\n",
       "       ['5.4', '3.4', '1.7', '0.2', 'Iris-setosa'],\n",
       "       ['5.1', '3.7', '1.5', '0.4', 'Iris-setosa'],\n",
       "       ['4.6', '3.6', '1.0', '0.2', 'Iris-setosa'],\n",
       "       ['5.1', '3.3', '1.7', '0.5', 'Iris-setosa'],\n",
       "       ['4.8', '3.4', '1.9', '0.2', 'Iris-setosa'],\n",
       "       ['5.0', '3.0', '1.6', '0.2', 'Iris-setosa'],\n",
       "       ['5.0', '3.4', '1.6', '0.4', 'Iris-setosa'],\n",
       "       ['5.2', '3.5', '1.5', '0.2', 'Iris-setosa'],\n",
       "       ['5.2', '3.4', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['4.7', '3.2', '1.6', '0.2', 'Iris-setosa'],\n",
       "       ['4.8', '3.1', '1.6', '0.2', 'Iris-setosa'],\n",
       "       ['5.4', '3.4', '1.5', '0.4', 'Iris-setosa'],\n",
       "       ['5.2', '4.1', '1.5', '0.1', 'Iris-setosa'],\n",
       "       ['5.5', '4.2', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'],\n",
       "       ['5.0', '3.2', '1.2', '0.2', 'Iris-setosa'],\n",
       "       ['5.5', '3.5', '1.3', '0.2', 'Iris-setosa'],\n",
       "       ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa'],\n",
       "       ['4.4', '3.0', '1.3', '0.2', 'Iris-setosa'],\n",
       "       ['5.1', '3.4', '1.5', '0.2', 'Iris-setosa'],\n",
       "       ['5.0', '3.5', '1.3', '0.3', 'Iris-setosa'],\n",
       "       ['4.5', '2.3', '1.3', '0.3', 'Iris-setosa'],\n",
       "       ['4.4', '3.2', '1.3', '0.2', 'Iris-setosa'],\n",
       "       ['5.0', '3.5', '1.6', '0.6', 'Iris-setosa'],\n",
       "       ['5.1', '3.8', '1.9', '0.4', 'Iris-setosa'],\n",
       "       ['4.8', '3.0', '1.4', '0.3', 'Iris-setosa'],\n",
       "       ['5.1', '3.8', '1.6', '0.2', 'Iris-setosa'],\n",
       "       ['4.6', '3.2', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['5.3', '3.7', '1.5', '0.2', 'Iris-setosa'],\n",
       "       ['5.0', '3.3', '1.4', '0.2', 'Iris-setosa'],\n",
       "       ['7.0', '3.2', '4.7', '1.4', 'Iris-versicolor'],\n",
       "       ['6.4', '3.2', '4.5', '1.5', 'Iris-versicolor'],\n",
       "       ['6.9', '3.1', '4.9', '1.5', 'Iris-versicolor'],\n",
       "       ['5.5', '2.3', '4.0', '1.3', 'Iris-versicolor'],\n",
       "       ['6.5', '2.8', '4.6', '1.5', 'Iris-versicolor'],\n",
       "       ['5.7', '2.8', '4.5', '1.3', 'Iris-versicolor'],\n",
       "       ['6.3', '3.3', '4.7', '1.6', 'Iris-versicolor'],\n",
       "       ['4.9', '2.4', '3.3', '1.0', 'Iris-versicolor'],\n",
       "       ['6.6', '2.9', '4.6', '1.3', 'Iris-versicolor'],\n",
       "       ['5.2', '2.7', '3.9', '1.4', 'Iris-versicolor'],\n",
       "       ['5.0', '2.0', '3.5', '1.0', 'Iris-versicolor'],\n",
       "       ['5.9', '3.0', '4.2', '1.5', 'Iris-versicolor'],\n",
       "       ['6.0', '2.2', '4.0', '1.0', 'Iris-versicolor'],\n",
       "       ['6.1', '2.9', '4.7', '1.4', 'Iris-versicolor'],\n",
       "       ['5.6', '2.9', '3.6', '1.3', 'Iris-versicolor'],\n",
       "       ['6.7', '3.1', '4.4', '1.4', 'Iris-versicolor'],\n",
       "       ['5.6', '3.0', '4.5', '1.5', 'Iris-versicolor'],\n",
       "       ['5.8', '2.7', '4.1', '1.0', 'Iris-versicolor'],\n",
       "       ['6.2', '2.2', '4.5', '1.5', 'Iris-versicolor'],\n",
       "       ['5.6', '2.5', '3.9', '1.1', 'Iris-versicolor'],\n",
       "       ['5.9', '3.2', '4.8', '1.8', 'Iris-versicolor'],\n",
       "       ['6.1', '2.8', '4.0', '1.3', 'Iris-versicolor'],\n",
       "       ['6.3', '2.5', '4.9', '1.5', 'Iris-versicolor'],\n",
       "       ['6.1', '2.8', '4.7', '1.2', 'Iris-versicolor'],\n",
       "       ['6.4', '2.9', '4.3', '1.3', 'Iris-versicolor'],\n",
       "       ['6.6', '3.0', '4.4', '1.4', 'Iris-versicolor'],\n",
       "       ['6.8', '2.8', '4.8', '1.4', 'Iris-versicolor'],\n",
       "       ['6.7', '3.0', '5.0', '1.7', 'Iris-versicolor'],\n",
       "       ['6.0', '2.9', '4.5', '1.5', 'Iris-versicolor'],\n",
       "       ['5.7', '2.6', '3.5', '1.0', 'Iris-versicolor'],\n",
       "       ['5.5', '2.4', '3.8', '1.1', 'Iris-versicolor'],\n",
       "       ['5.5', '2.4', '3.7', '1.0', 'Iris-versicolor'],\n",
       "       ['5.8', '2.7', '3.9', '1.2', 'Iris-versicolor'],\n",
       "       ['6.0', '2.7', '5.1', '1.6', 'Iris-versicolor'],\n",
       "       ['5.4', '3.0', '4.5', '1.5', 'Iris-versicolor'],\n",
       "       ['6.0', '3.4', '4.5', '1.6', 'Iris-versicolor'],\n",
       "       ['6.7', '3.1', '4.7', '1.5', 'Iris-versicolor'],\n",
       "       ['6.3', '2.3', '4.4', '1.3', 'Iris-versicolor'],\n",
       "       ['5.6', '3.0', '4.1', '1.3', 'Iris-versicolor'],\n",
       "       ['5.5', '2.5', '4.0', '1.3', 'Iris-versicolor'],\n",
       "       ['5.5', '2.6', '4.4', '1.2', 'Iris-versicolor'],\n",
       "       ['6.1', '3.0', '4.6', '1.4', 'Iris-versicolor'],\n",
       "       ['5.8', '2.6', '4.0', '1.2', 'Iris-versicolor'],\n",
       "       ['5.0', '2.3', '3.3', '1.0', 'Iris-versicolor'],\n",
       "       ['5.6', '2.7', '4.2', '1.3', 'Iris-versicolor'],\n",
       "       ['5.7', '3.0', '4.2', '1.2', 'Iris-versicolor'],\n",
       "       ['5.7', '2.9', '4.2', '1.3', 'Iris-versicolor'],\n",
       "       ['6.2', '2.9', '4.3', '1.3', 'Iris-versicolor'],\n",
       "       ['5.1', '2.5', '3.0', '1.1', 'Iris-versicolor'],\n",
       "       ['5.7', '2.8', '4.1', '1.3', 'Iris-versicolor'],\n",
       "       ['6.3', '3.3', '6.0', '2.5', 'Iris-virginica'],\n",
       "       ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica'],\n",
       "       ['7.1', '3.0', '5.9', '2.1', 'Iris-virginica'],\n",
       "       ['6.3', '2.9', '5.6', '1.8', 'Iris-virginica'],\n",
       "       ['6.5', '3.0', '5.8', '2.2', 'Iris-virginica'],\n",
       "       ['7.6', '3.0', '6.6', '2.1', 'Iris-virginica'],\n",
       "       ['4.9', '2.5', '4.5', '1.7', 'Iris-virginica'],\n",
       "       ['7.3', '2.9', '6.3', '1.8', 'Iris-virginica'],\n",
       "       ['6.7', '2.5', '5.8', '1.8', 'Iris-virginica'],\n",
       "       ['7.2', '3.6', '6.1', '2.5', 'Iris-virginica'],\n",
       "       ['6.5', '3.2', '5.1', '2.0', 'Iris-virginica'],\n",
       "       ['6.4', '2.7', '5.3', '1.9', 'Iris-virginica'],\n",
       "       ['6.8', '3.0', '5.5', '2.1', 'Iris-virginica'],\n",
       "       ['5.7', '2.5', '5.0', '2.0', 'Iris-virginica'],\n",
       "       ['5.8', '2.8', '5.1', '2.4', 'Iris-virginica'],\n",
       "       ['6.4', '3.2', '5.3', '2.3', 'Iris-virginica'],\n",
       "       ['6.5', '3.0', '5.5', '1.8', 'Iris-virginica'],\n",
       "       ['7.7', '3.8', '6.7', '2.2', 'Iris-virginica'],\n",
       "       ['7.7', '2.6', '6.9', '2.3', 'Iris-virginica'],\n",
       "       ['6.0', '2.2', '5.0', '1.5', 'Iris-virginica'],\n",
       "       ['6.9', '3.2', '5.7', '2.3', 'Iris-virginica'],\n",
       "       ['5.6', '2.8', '4.9', '2.0', 'Iris-virginica'],\n",
       "       ['7.7', '2.8', '6.7', '2.0', 'Iris-virginica'],\n",
       "       ['6.3', '2.7', '4.9', '1.8', 'Iris-virginica'],\n",
       "       ['6.7', '3.3', '5.7', '2.1', 'Iris-virginica'],\n",
       "       ['7.2', '3.2', '6.0', '1.8', 'Iris-virginica'],\n",
       "       ['6.2', '2.8', '4.8', '1.8', 'Iris-virginica'],\n",
       "       ['6.1', '3.0', '4.9', '1.8', 'Iris-virginica'],\n",
       "       ['6.4', '2.8', '5.6', '2.1', 'Iris-virginica'],\n",
       "       ['7.2', '3.0', '5.8', '1.6', 'Iris-virginica'],\n",
       "       ['7.4', '2.8', '6.1', '1.9', 'Iris-virginica'],\n",
       "       ['7.9', '3.8', '6.4', '2.0', 'Iris-virginica'],\n",
       "       ['6.4', '2.8', '5.6', '2.2', 'Iris-virginica'],\n",
       "       ['6.3', '2.8', '5.1', '1.5', 'Iris-virginica'],\n",
       "       ['6.1', '2.6', '5.6', '1.4', 'Iris-virginica'],\n",
       "       ['7.7', '3.0', '6.1', '2.3', 'Iris-virginica'],\n",
       "       ['6.3', '3.4', '5.6', '2.4', 'Iris-virginica'],\n",
       "       ['6.4', '3.1', '5.5', '1.8', 'Iris-virginica'],\n",
       "       ['6.0', '3.0', '4.8', '1.8', 'Iris-virginica'],\n",
       "       ['6.9', '3.1', '5.4', '2.1', 'Iris-virginica'],\n",
       "       ['6.7', '3.1', '5.6', '2.4', 'Iris-virginica'],\n",
       "       ['6.9', '3.1', '5.1', '2.3', 'Iris-virginica'],\n",
       "       ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica'],\n",
       "       ['6.8', '3.2', '5.9', '2.3', 'Iris-virginica'],\n",
       "       ['6.7', '3.3', '5.7', '2.5', 'Iris-virginica'],\n",
       "       ['6.7', '3.0', '5.2', '2.3', 'Iris-virginica'],\n",
       "       ['6.3', '2.5', '5.0', '1.9', 'Iris-virginica'],\n",
       "       ['6.5', '3.0', '5.2', '2.0', 'Iris-virginica'],\n",
       "       ['6.2', '3.4', '5.4', '2.3', 'Iris-virginica'],\n",
       "       ['5.9', '3.0', '5.1', '1.8', 'Iris-virginica']], dtype='<U15')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = create_train_data()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prior_probability(train_data):\n",
    "    # cách 1\n",
    "    # y_unique = np.unique(train_data[:, -1], return_counts=True)\n",
    "    # prior_probability = np.zeros(len(y_unique[0]))\n",
    "    # for i in range(len(y_unique)):\n",
    "    #     prior_probability[i] = len(\n",
    "    #         np.where(train_data[:, -1] == y_unique[i])[0]) / len(train_data[:, -1])\n",
    "\n",
    "    # cách 2\n",
    "    y_unique, counts = np.unique(train_data[:, -1], return_counts=True)\n",
    "    prior_probability = counts / np.sum(counts)\n",
    "    return prior_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_prior_probability(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std_features_uniques(train_data):\n",
    "    y_unique = np.unique(train_data[:, -1])\n",
    "    # mean, standard deviation (trung bình, độ lệch chuẩn)\n",
    "    mean_std_features = []\n",
    "    for i in range(train_data.shape[1]-1):\n",
    "        feature_unique_mean_std = np.zeros((len(y_unique), 2))\n",
    "        for j in range(len(y_unique)):\n",
    "            data_feature_unique = (train_data[:, i][np.where(\n",
    "                train_data[:, -1] == y_unique[j])]).astype(float)\n",
    "            mean_feature_unique = np.mean(data_feature_unique)\n",
    "            std_feature_unique = np.std(data_feature_unique)\n",
    "            feature_unique_mean_std[j] = [\n",
    "                mean_feature_unique, std_feature_unique]\n",
    "        mean_std_features.append(feature_unique_mean_std)\n",
    "    return mean_std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.006     , 0.34894699],\n",
       "        [5.936     , 0.51098337],\n",
       "        [6.588     , 0.62948868]]),\n",
       " array([[3.418     , 0.37719491],\n",
       "        [2.77      , 0.31064449],\n",
       "        [2.974     , 0.31925538]]),\n",
       " array([[1.464     , 0.17176728],\n",
       "        [4.26      , 0.46518813],\n",
       "        [5.552     , 0.54634787]]),\n",
       " array([[0.244     , 0.10613199],\n",
       "        [1.326     , 0.19576517],\n",
       "        [2.026     , 0.27188968]])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_features = compute_mean_std_features_uniques(train_data)\n",
    "mean_std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gaussian_naive_bayes(train_data):\n",
    "    prior_probability = compute_prior_probability(train_data)\n",
    "    mean_std_features = compute_mean_std_features_uniques(train_data)\n",
    "    return prior_probability, mean_std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, mean, std):\n",
    "    return (1/(std * np.sqrt(2*np.pi))) * (np.e**(-(x - mean)**2 / (2 * std**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_iris(X, prior_probability, mean_std_features):\n",
    "    posteriors = np.zeros(len(prior_probability))\n",
    "    for i in range(len(mean_std_features[0])):\n",
    "        posterior = prior_probability[i]\n",
    "        for j in range(len(X)):\n",
    "            condition_probability_xi = gauss(X[j],\n",
    "                                             mean_std_features[j][i, 0],\n",
    "                                             mean_std_features[j][i, 1])\n",
    "            posterior *= condition_probability_xi\n",
    "        posteriors[i] = posterior\n",
    "    return np.argmax(posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# X =[ sepal length , sepal width , petal length , petal width ]\n",
    "X = [6.3, 3.3, 6.0, 2.5]\n",
    "train_data = create_train_data()\n",
    "y_unique = np.unique(train_data[:, 4])\n",
    "prior_probability, mean_std_features = train_gaussian_naive_bayes(train_data)\n",
    "pred = y_unique[prediction_iris(X, prior_probability, mean_std_features)]\n",
    "print(pred)\n",
    "assert pred == \"Iris-virginica\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 #########################\n",
    "# X =[ sepal length , sepal width , petal length , petal width ]\n",
    "X = [5.0, 2.0, 3.5, 1.0]\n",
    "train_data = create_train_data()\n",
    "y_unique = np.unique(train_data[:, 4])\n",
    "prior_probability, mean_std_features = train_gaussian_naive_bayes(train_data)\n",
    "pred = y_unique[prediction_iris(X, prior_probability, mean_std_features)]\n",
    "assert pred == \"Iris-versicolor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3 #########################\n",
    "X = [4.9, 3.1, 1.5, 0.1]\n",
    "# X =[ sepal length , sepal width , petal length , petal width ]\n",
    "train_data = create_train_data()\n",
    "y_unique = np . unique(train_data[:, 4])\n",
    "prior_probability, mean_std_features = train_gaussian_naive_bayes(train_data)\n",
    "pred = y_unique[prediction_iris(X, prior_probability, mean_std_features)]\n",
    "assert pred == \"Iris-setosa\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
